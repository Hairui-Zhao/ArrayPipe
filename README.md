# ArrayPipe：面向批量提交作业的并行框架
**对应文章第3章**

**ArrayPipe：面向大模型超参数搜索的高吞吐训练框架**

在大语言模型等大型模型的探索性训练（如超参数调优）中，用户常需批量提交大量结构相同、配置各异的“孪生作业”。传统流水线并行（PP）模式让每个作业独占资源串行执行，导致GPU存在大量空闲“气泡”，资源利用率与训练吞吐量低下。

针对此问题，我们提出了 **ArrayPipe** 框架。其核心创新在于 **作业数组并行（JAP）** 范式。ArrayPipe 将一批孪生作业打包，形成一个统一的作业数组，允许多个作业共享同一组GPU资源并发执行。通过让不同作业的计算任务交织填充流水线的空闲时段，它能显著减少气泡，最大化硬件利用率。

框架内置了三大关键支撑技术：实现孪生作业间**低开销上下文切换**的机制，以克服频繁作业切换带来的延迟；针对作业执行时间不均的**高效调度算法**，动态编排任务执行顺序以最小化迭代时间；以及应对多模型状态共存压力的**内存管理器**，保障训练稳定性。

实验表明，与最先进的PP方法相比，ArrayPipe能够将此类探索性训练任务的平均吞吐量提升最高达 **1.52倍**，为加速模型开发与调优流程提供了强有力的系统级支持。
